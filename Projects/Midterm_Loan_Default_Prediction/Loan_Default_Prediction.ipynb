{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46e5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan Default Prediction\n",
    "\n",
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006adf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dataset Loaded Successfully!\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Customer_ID           300 non-null    object\n",
      " 1   Age                   300 non-null    int64 \n",
      " 2   Gender                300 non-null    object\n",
      " 3   Employment_Type       300 non-null    object\n",
      " 4   Monthly_Income        300 non-null    int64 \n",
      " 5   Loan_Amount           300 non-null    int64 \n",
      " 6   Loan_Term_Months      300 non-null    int64 \n",
      " 7   Credit_Score          300 non-null    int64 \n",
      " 8   Existing_Loans_Count  300 non-null    int64 \n",
      " 9   Previous_Default      300 non-null    int64 \n",
      " 10  EMI_Burden            300 non-null    int64 \n",
      " 11  Default               300 non-null    int64 \n",
      " 12  Loan_Date             300 non-null    object\n",
      " 13  Loan_Year             300 non-null    int64 \n",
      "dtypes: int64(10), object(4)\n",
      "memory usage: 32.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Load Dataset\n",
    "df = pd.read_csv(r'D:\\Github_Share\\Dataset\\ameen_dataset.csv')\n",
    "print(\"\\n‚úÖ Dataset Loaded Successfully!\\n\")\n",
    "print(df.info())  # check data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c198378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age  Monthly_Income    Loan_Amount  Loan_Term_Months  \\\n",
      "count  300.000000      300.000000     300.000000         300.00000   \n",
      "mean    42.696667    84387.816667  532007.393333          36.40000   \n",
      "std     13.048328    42000.322861  272304.042724          17.16339   \n",
      "min     21.000000    10126.000000   54263.000000          12.00000   \n",
      "25%     31.000000    50711.250000  295488.250000          24.00000   \n",
      "50%     44.000000    85690.000000  549879.500000          36.00000   \n",
      "75%     54.000000   121105.750000  745143.000000          48.00000   \n",
      "max     64.000000   149789.000000  999491.000000          60.00000   \n",
      "\n",
      "       Credit_Score  Existing_Loans_Count  Previous_Default    EMI_Burden  \\\n",
      "count    300.000000            300.000000        300.000000    300.000000   \n",
      "mean     594.056667              2.093333          0.120000  23143.456667   \n",
      "std      171.858346              1.401608          0.325504  13598.386578   \n",
      "min      300.000000              0.000000          0.000000   2097.000000   \n",
      "25%      446.000000              1.000000          0.000000  11488.250000   \n",
      "50%      601.000000              2.000000          0.000000  21515.000000   \n",
      "75%      726.000000              3.000000          0.000000  33704.250000   \n",
      "max      898.000000              4.000000          1.000000  49945.000000   \n",
      "\n",
      "          Default    Loan_Year  \n",
      "count  300.000000   300.000000  \n",
      "mean     0.200000  2023.380000  \n",
      "std      0.400668     0.954973  \n",
      "min      0.000000  2022.000000  \n",
      "25%      0.000000  2023.000000  \n",
      "50%      0.000000  2023.000000  \n",
      "75%      0.000000  2024.000000  \n",
      "max      1.000000  2025.000000  \n",
      "Customer_ID             0\n",
      "Age                     0\n",
      "Gender                  0\n",
      "Employment_Type         0\n",
      "Monthly_Income          0\n",
      "Loan_Amount             0\n",
      "Loan_Term_Months        0\n",
      "Credit_Score            0\n",
      "Existing_Loans_Count    0\n",
      "Previous_Default        0\n",
      "EMI_Burden              0\n",
      "Default                 0\n",
      "Loan_Date               0\n",
      "Loan_Year               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Basic EDA\n",
    "print(df.describe())\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06103668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Target and Drop Columns\n",
    "target = 'Default'\n",
    "columns_to_drop = ['Customer_ID', 'Loan_Date']\n",
    "x = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2065287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Column Classification:\n",
      "  - Yes/No Columns: ['Gender', 'Employment_Type', 'Previous_Default']\n",
      "  - Categorical Columns: ['Loan_Year']\n",
      "  - Numerical Columns: ['Age', 'Monthly_Income', 'Loan_Amount', 'Loan_Term_Months', 'Credit_Score', 'Existing_Loans_Count', 'EMI_Burden']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Classify Columns\n",
    "yes_no_columns = []\n",
    "cat_columns = []\n",
    "num_columns = []\n",
    "\n",
    "for column in x.columns:\n",
    "    if column in columns_to_drop:\n",
    "        continue\n",
    "    elif x[column].nunique() == 2:\n",
    "        yes_no_columns.append(column)\n",
    "    elif x[column].nunique() <= 4:\n",
    "        cat_columns.append(column)\n",
    "    else:\n",
    "        num_columns.append(column)\n",
    "\n",
    "print(\"‚úÖ Column Classification:\")\n",
    "print(\"  - Yes/No Columns:\", yes_no_columns)\n",
    "print(\"  - Categorical Columns:\", cat_columns)\n",
    "print(\"  - Numerical Columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6da36558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Preprocessing Steps\n",
    "def drop_columns(X):\n",
    "    return X.drop(columns=columns_to_drop)\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('scale_num', StandardScaler(), num_columns),\n",
    "    ('encode_cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), cat_columns),\n",
    "    ('encode_yn', OrdinalEncoder(), yes_no_columns)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582e8795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train-Test Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025befeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 240 entries, 232 to 102\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Customer_ID           240 non-null    object\n",
      " 1   Age                   240 non-null    int64 \n",
      " 2   Gender                240 non-null    object\n",
      " 3   Employment_Type       240 non-null    object\n",
      " 4   Monthly_Income        240 non-null    int64 \n",
      " 5   Loan_Amount           240 non-null    int64 \n",
      " 6   Loan_Term_Months      240 non-null    int64 \n",
      " 7   Credit_Score          240 non-null    int64 \n",
      " 8   Existing_Loans_Count  240 non-null    int64 \n",
      " 9   Previous_Default      240 non-null    int64 \n",
      " 10  EMI_Burden            240 non-null    int64 \n",
      " 11  Loan_Date             240 non-null    object\n",
      " 12  Loan_Year             240 non-null    int64 \n",
      "dtypes: int64(9), object(4)\n",
      "memory usage: 26.2+ KB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998bd78a",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c2c5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Logistic Regression Report:\n",
      "Accuracy: 0.9166666666666666\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        49\n",
      "           1       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.92        60\n",
      "   macro avg       0.87      0.84      0.86        60\n",
      "weighted avg       0.91      0.92      0.92        60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[47  2]\n",
      " [ 3  8]]\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "log_train_pipeline = Pipeline([\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('model', log_model)\n",
    "])\n",
    "\n",
    "log_train_pipeline.fit(x_train, y_train)\n",
    "y_pred_log = log_train_pipeline.predict(x_test)\n",
    "\n",
    "print(\"\\nüîπ Logistic Regression Report:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26618bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to 'models\\logistic_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save model to file\n",
    "import joblib\n",
    "filename = r'models\\logistic_model.pkl'\n",
    "joblib.dump(log_model, filename)\n",
    "print(f\"‚úÖ Model saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09a0a1",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea747f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ SVM Classification Report:\n",
      "Accuracy: 0.8833333333333333\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        49\n",
      "           1       1.00      0.36      0.53        11\n",
      "\n",
      "    accuracy                           0.88        60\n",
      "   macro avg       0.94      0.68      0.73        60\n",
      "weighted avg       0.90      0.88      0.86        60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49  0]\n",
      " [ 7  4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the SVM model\n",
    "svm_model = SVC(kernel='rbf', probability=True)  \n",
    "\n",
    "#  SVM model\n",
    "svm_train_pipeline = Pipeline([\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('model', svm_model)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "svm_train_pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_train_pipeline.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nüîπ SVM Classification Report:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3276f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to 'models\\svm_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save model to file\n",
    "import joblib\n",
    "filename = r'models\\svm_model.pkl'\n",
    "joblib.dump(svm_model, filename)\n",
    "print(f\"‚úÖ Model saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb34778",
   "metadata": {},
   "source": [
    "# Random Forests Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f510f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Random Forest Classification Report:\n",
      "Accuracy: 0.9833333333333333\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        49\n",
      "           1       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.99      0.95      0.97        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n",
      "Confusion Matrix:\n",
      " [[49  0]\n",
      " [ 1 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Random Forest model\n",
    "rf_train_pipeline = Pipeline([\n",
    "    ('drop_columns', FunctionTransformer(drop_columns)),\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('model', rf_model)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "rf_train_pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_train_pipeline.predict(x_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nüîπ Random Forest Classification Report:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4422f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to 'models\\rf_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save model to file\n",
    "import joblib\n",
    "filename = r'models\\rf_model.pkl'\n",
    "joblib.dump(rf_model, filename)\n",
    "print(f\"‚úÖ Model saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6be72a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Monthly_Income', 'Loan_Amount', 'Loan_Term_Months', 'Credit_Score', 'Existing_Loans_Count', 'EMI_Burden', 'Loan_Year_2022', 'Loan_Year_2023', 'Loan_Year_2024', 'Loan_Year_2025', 'Gender_ordinal', 'Employment_Type_ordinal', 'Previous_Default_ordinal']\n",
      "Total features: 14\n"
     ]
    }
   ],
   "source": [
    "preprocessor = rf_train_pipeline.named_steps['preprocessing']\n",
    "\n",
    "num_features = preprocessor.named_transformers_['scale_num'].get_feature_names_out(num_columns)\n",
    "cat_features = preprocessor.named_transformers_['encode_cat'].get_feature_names_out(cat_columns)\n",
    "yn_features = [f\"{col}_ordinal\" for col in yes_no_columns]\n",
    "\n",
    "final_features = list(num_features) + list(cat_features) + yn_features\n",
    "print(final_features)\n",
    "print(f\"Total features: {len(final_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb6f4b",
   "metadata": {},
   "source": [
    "# Synthetic Data Generator Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac4c5042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic dataset with 14 features saved to:\n",
      "D:/Github_Share/Dataset/new_loan_testing.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       300 non-null    int32  \n",
      " 1   Monthly_Income            300 non-null    int32  \n",
      " 2   Loan_Amount               300 non-null    int32  \n",
      " 3   Loan_Term_Months          300 non-null    int64  \n",
      " 4   Credit_Score              300 non-null    int32  \n",
      " 5   Existing_Loans_Count      300 non-null    int32  \n",
      " 6   EMI_Burden                300 non-null    float64\n",
      " 7   Loan_Year_2022            300 non-null    int64  \n",
      " 8   Loan_Year_2023            300 non-null    int64  \n",
      " 9   Loan_Year_2024            300 non-null    int64  \n",
      " 10  Loan_Year_2025            300 non-null    int64  \n",
      " 11  Gender_ordinal            300 non-null    int64  \n",
      " 12  Employment_Type_ordinal   300 non-null    int64  \n",
      " 13  Previous_Default_ordinal  300 non-null    int64  \n",
      "dtypes: float64(1), int32(5), int64(8)\n",
      "memory usage: 27.1 KB\n",
      "Total features: 14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 300\n",
    "\n",
    "# Numeric features\n",
    "Age = np.random.randint(21, 60, size=n)\n",
    "Monthly_Income = np.random.randint(20000, 150000, size=n)\n",
    "Loan_Amount = np.random.randint(50000, 500000, size=n)\n",
    "Loan_Term_Months = np.random.choice([12, 24, 36, 48, 60], size=n)\n",
    "Credit_Score = np.random.randint(300, 850, size=n)\n",
    "Existing_Loans_Count = np.random.randint(0, 5, size=n)\n",
    "EMI_Burden = np.round(np.random.uniform(0.1, 0.5, size=n), 3)\n",
    "\n",
    "# One-hot encoded Loan_Year columns (exactly one per sample)\n",
    "Loan_Year_2022 = np.zeros(n, dtype=int)\n",
    "Loan_Year_2023 = np.zeros(n, dtype=int)\n",
    "Loan_Year_2024 = np.zeros(n, dtype=int)\n",
    "Loan_Year_2025 = np.zeros(n, dtype=int)\n",
    "\n",
    "for i in range(n):\n",
    "    chosen = np.random.choice(4)\n",
    "    if chosen == 0:\n",
    "        Loan_Year_2022[i] = 1\n",
    "    elif chosen == 1:\n",
    "        Loan_Year_2023[i] = 1\n",
    "    elif chosen == 2:\n",
    "        Loan_Year_2024[i] = 1\n",
    "    else:\n",
    "        Loan_Year_2025[i] = 1\n",
    "\n",
    "# Ordinal encoded categorical columns\n",
    "Gender_ordinal = np.random.choice([0, 1], size=n)  # Male=0, Female=1\n",
    "Employment_Type_ordinal = np.random.choice([0, 1, 2], size=n)  # Salaried=0, Self-Employed=1, Unemployed=2\n",
    "Previous_Default_ordinal = np.random.choice([0, 1], size=n)  # No=0, Yes=1\n",
    "\n",
    "# Create final DataFrame\n",
    "df_final = pd.DataFrame({\n",
    "    'Age': Age,\n",
    "    'Monthly_Income': Monthly_Income,\n",
    "    'Loan_Amount': Loan_Amount,\n",
    "    'Loan_Term_Months': Loan_Term_Months,\n",
    "    'Credit_Score': Credit_Score,\n",
    "    'Existing_Loans_Count': Existing_Loans_Count,\n",
    "    'EMI_Burden': EMI_Burden,\n",
    "    'Loan_Year_2022': Loan_Year_2022,\n",
    "    'Loan_Year_2023': Loan_Year_2023,\n",
    "    'Loan_Year_2024': Loan_Year_2024,\n",
    "    'Loan_Year_2025': Loan_Year_2025,\n",
    "    'Gender_ordinal': Gender_ordinal,\n",
    "    'Employment_Type_ordinal': Employment_Type_ordinal,\n",
    "    'Previous_Default_ordinal': Previous_Default_ordinal,\n",
    "})\n",
    "\n",
    "# Save to CSV file\n",
    "csv_path = \"D:/Github_Share/Dataset/new_loan_testing.csv\"\n",
    "df_final.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Synthetic dataset with 14 features saved to:\\n{csv_path}\")\n",
    "df_final.info()\n",
    "print(\"Total features:\", df_final.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e8e66ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic x_test saved to:None\n",
      "Synthetic y_test saved to:None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 14 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   Age                       300 non-null    int32\n",
      " 1   Monthly_Income            300 non-null    int32\n",
      " 2   Loan_Amount               300 non-null    int32\n",
      " 3   Loan_Term_Months          300 non-null    int64\n",
      " 4   Credit_Score              300 non-null    int32\n",
      " 5   Existing_Loans_Count      300 non-null    int32\n",
      " 6   EMI_Burden                300 non-null    int32\n",
      " 7   Loan_Year_2022            300 non-null    int64\n",
      " 8   Loan_Year_2023            300 non-null    int64\n",
      " 9   Loan_Year_2024            300 non-null    int64\n",
      " 10  Loan_Year_2025            300 non-null    int64\n",
      " 11  Gender_ordinal            300 non-null    int64\n",
      " 12  Employment_Type_ordinal   300 non-null    int64\n",
      " 13  Previous_Default_ordinal  300 non-null    int64\n",
      "dtypes: int32(6), int64(8)\n",
      "memory usage: 25.9 KB\n",
      "\n",
      "Total features in x_test: 14\n",
      "\n",
      "Sample target distribution:\n",
      "Default\n",
      "0    0.526667\n",
      "1    0.473333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 300\n",
    "\n",
    "# Numeric features\n",
    "Age = np.random.randint(21, 60, size=n)\n",
    "Monthly_Income = np.random.randint(20000, 150000, size=n)\n",
    "Loan_Amount = np.random.randint(50000, 500000, size=n)\n",
    "Loan_Term_Months = np.random.choice([12, 24, 36, 48, 60], size=n)\n",
    "Credit_Score = np.random.randint(300, 850, size=n)\n",
    "Existing_Loans_Count = np.random.randint(0, 5, size=n)\n",
    "EMI_Burden = np.random.randint(1000, 25000, size=n)  # Changed to int to match your previous data\n",
    "\n",
    "# One-hot encoded Loan_Year columns (exactly one per sample)\n",
    "Loan_Year_2022 = np.zeros(n, dtype=int)\n",
    "Loan_Year_2023 = np.zeros(n, dtype=int)\n",
    "Loan_Year_2024 = np.zeros(n, dtype=int)\n",
    "Loan_Year_2025 = np.zeros(n, dtype=int)\n",
    "\n",
    "for i in range(n):\n",
    "    chosen = np.random.choice(4)\n",
    "    if chosen == 0:\n",
    "        Loan_Year_2022[i] = 1\n",
    "    elif chosen == 1:\n",
    "        Loan_Year_2023[i] = 1\n",
    "    elif chosen == 2:\n",
    "        Loan_Year_2024[i] = 1\n",
    "    else:\n",
    "        Loan_Year_2025[i] = 1\n",
    "\n",
    "# Ordinal encoded categorical columns\n",
    "Gender_ordinal = np.random.choice([0, 1], size=n)  # Male=0, Female=1\n",
    "Employment_Type_ordinal = np.random.choice([0, 1, 2], size=n)  # Salaried=0, Self-Employed=1, Unemployed=2\n",
    "Previous_Default_ordinal = np.random.choice([0, 1], size=n)  # No=0, Yes=1\n",
    "\n",
    "# Binary target variable\n",
    "Default = np.random.choice([0, 1], size=n)\n",
    "\n",
    "# Create final DataFrame\n",
    "df_final = pd.DataFrame({\n",
    "    'Age': Age,\n",
    "    'Monthly_Income': Monthly_Income,\n",
    "    'Loan_Amount': Loan_Amount,\n",
    "    'Loan_Term_Months': Loan_Term_Months,\n",
    "    'Credit_Score': Credit_Score,\n",
    "    'Existing_Loans_Count': Existing_Loans_Count,\n",
    "    'EMI_Burden': EMI_Burden,\n",
    "    'Loan_Year_2022': Loan_Year_2022,\n",
    "    'Loan_Year_2023': Loan_Year_2023,\n",
    "    'Loan_Year_2024': Loan_Year_2024,\n",
    "    'Loan_Year_2025': Loan_Year_2025,\n",
    "    'Gender_ordinal': Gender_ordinal,\n",
    "    'Employment_Type_ordinal': Employment_Type_ordinal,\n",
    "    'Previous_Default_ordinal': Previous_Default_ordinal,\n",
    "    'Default': Default\n",
    "})\n",
    "\n",
    "# Split features and target\n",
    "x_testing = df_final.drop(columns=['Default'])\n",
    "y_testing = df_final['Default']\n",
    "\n",
    "# Save to CSV files\n",
    "\n",
    "x_path=x_testing.to_csv(\"D:/Github_Share/Dataset/x_testing.csv\", index=False)\n",
    "y_path=y_testing.to_csv(\"D:/Github_Share/Dataset/y_testing.csv\", index=False)\n",
    "\n",
    "print(f\"Synthetic x_test saved to:{x_path}\")\n",
    "print(f\"Synthetic y_test saved to:{y_path}\")\n",
    "\n",
    "print(\"\\nX_test info:\")\n",
    "x_testing.info()\n",
    "print(\"\\nTotal features in x_test:\", x_testing.shape[1])\n",
    "print(\"\\nSample target distribution:\")\n",
    "print(y_testing.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029d8ab",
   "metadata": {},
   "source": [
    "# Run All 3 Models with Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91bd6912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (300, 14)\n",
      "y_test shape: (300,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\pyenv\\pyenv-win\\versions\\3.12.3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression] Accuracy logged: 0.53\n",
      "[Logistic Regression] Model logged to MLflow by thread Thread-3 (log_model_run).\n",
      "[SVM] Accuracy logged: 0.5266666666666666\n",
      "[SVM] Model logged to MLflow by thread Thread-4 (log_model_run).\n",
      "üèÉ View run Logistic Regression at: http://127.0.0.1:5000/#/experiments/126304146287965710/runs/73d247e982ea4ef3ad5d6e0373020b9c\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/126304146287965710\n",
      "üèÉ View run SVM at: http://127.0.0.1:5000/#/experiments/126304146287965710/runs/61f2f6a3d78c4f36a893ae2d57e23ee2\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/126304146287965710\n",
      "[Random Forest] Accuracy logged: 0.49666666666666665\n",
      "[Random Forest] Model logged to MLflow by thread Thread-5 (log_model_run).\n",
      "üèÉ View run Random Forest at: http://127.0.0.1:5000/#/experiments/126304146287965710/runs/69ab625d5ea64ffb86672d294abcecad\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/126304146287965710\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "import threading\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://127.0.0.1:5000\"\n",
    "EXPERIMENT_NAME = \"Pretrained_Model_Logging\"\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "models_info = [\n",
    "    {\"file\": r\"models\\logistic_model.pkl\", \"name\": \"Logistic Regression\"},\n",
    "    {\"file\": r\"models\\svm_model.pkl\", \"name\": \"SVM\"},\n",
    "    {\"file\": r\"models\\rf_model.pkl\", \"name\": \"Random Forest\"}\n",
    "]\n",
    "\n",
    "# Load test data (adjust paths as needed)\n",
    "X_test = pd.read_csv(r'D:\\Github_Share\\Dataset\\x_testing.csv')\n",
    "y_test = pd.read_csv(r'D:\\Github_Share\\Dataset\\y_testing.csv').squeeze()  # Convert to Series if possible\n",
    "\n",
    "print(f\"X_test shape: {X_test.shape}\", flush=True)\n",
    "print(f\"y_test shape: {y_test.shape}\", flush=True)\n",
    "\n",
    "def log_model_run(model_file, model_name, X_test=None, y_test=None):\n",
    "    try:\n",
    "        model_path = Path(model_file)\n",
    "        if not model_path.exists():\n",
    "            print(f\"[{model_name}] Model file not found: {model_file}\", flush=True)\n",
    "            return\n",
    "\n",
    "        model = joblib.load(model_path)\n",
    "        thread_name = threading.current_thread().name\n",
    "\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            mlflow.set_tag(\"model_type\", model_name)\n",
    "\n",
    "            # Log model parameters if available\n",
    "            try:\n",
    "                params = model.get_params()\n",
    "                for param_name, param_value in params.items():\n",
    "                    mlflow.log_param(param_name, param_value)\n",
    "            except Exception:\n",
    "                print(f\"[{model_name}] Could not get parameters from model.\", flush=True)\n",
    "\n",
    "            # Prepare input_example and signature for MLflow\n",
    "            signature = None\n",
    "            input_example = None\n",
    "            if X_test is not None:\n",
    "                try:\n",
    "                    input_example = X_test.head(5)\n",
    "                    preds_example = model.predict(input_example)\n",
    "                    signature = infer_signature(input_example, preds_example)\n",
    "                except Exception as e:\n",
    "                    print(f\"[{model_name}] Could not infer signature: {e}\", flush=True)\n",
    "\n",
    "            # Log model with signature and input_example\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"model\", signature=signature, input_example=input_example)\n",
    "\n",
    "            # Log accuracy metric if test data provided\n",
    "            if X_test is not None and y_test is not None:\n",
    "                try:\n",
    "                    preds = model.predict(X_test.values)  # avoid sklearn warning by removing feature names\n",
    "                    acc = accuracy_score(y_test, preds)\n",
    "                    mlflow.log_metric(\"accuracy\", acc)\n",
    "                    print(f\"[{model_name}] Accuracy logged: {acc}\", flush=True)\n",
    "                except Exception as e:\n",
    "                    print(f\"[{model_name}] Failed to log accuracy metric: {e}\", flush=True)\n",
    "\n",
    "            print(f\"[{model_name}] Model logged to MLflow by thread {thread_name}.\", flush=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{model_name}] Error during logging: {e}\", flush=True)\n",
    "\n",
    "threads = []\n",
    "for model_info in models_info:\n",
    "    t = threading.Thread(target=log_model_run, args=(model_info[\"file\"], model_info[\"name\"], X_test, y_test))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5ae46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
